**ğŸ“˜ Day 1 â€“ Regression Basics**

ğŸ“– Concepts Learned
- Linear Regression: Fits a straight line to predict continuous values.
- Logistic Regression: Used for classification problems (yes/no, true/false).
- Sigmoid Function: Converts outputs into probabilities between 0 and 1.
- ReLU (Rectified Linear Unit): Keeps positive values, turns negatives into 0.

ğŸ§ª Examples & Practice
- Implemented Linear Regression to predict house prices based on size.
- Implemented Logistic Regression to predict Titanic survival.
- Plotted the Sigmoid curve to visualize probability outputs.

ğŸ”‘ Key Takeaways
- Linear regression is about drawing the best line to predict numbers.
- Logistic regression predicts probabilities for classification tasks.
- Sigmoid is perfect for probabilities, while ReLU helps neural networks learn faster.
- Metrics like RÂ² and Accuracy help measure how well models perform.

ğŸ“Š Metrics Learned
- RÂ² (R-squared): Measures how well the regression line fits the data.
- Accuracy: Measures how many predictions are correct in classification.

ğŸ“ Reflections
- Linear regression felt intuitive â€” like drawing a line through points.
- Logistic regression was clearer after visualizing the sigmoid curve.
- Understanding activation functions (Sigmoid & ReLU) gave insight into how neural networks process information.
- Coding practice helped connect theory with real examples.


